{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from transformers import BertTokenizer, BertForSequenceClassification\nimport torch\nimport torch.nn as nn\n\nimport pandas as pd\nimport numpy as np","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-17T14:01:46.932457Z","iopub.execute_input":"2023-09-17T14:01:46.932875Z","iopub.status.idle":"2023-09-17T14:01:59.660174Z","shell.execute_reply.started":"2023-09-17T14:01:46.932838Z","shell.execute_reply":"2023-09-17T14:01:59.659239Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Loading and reading data","metadata":{}},{"cell_type":"code","source":"df_train = pd.read_csv(\"/kaggle/input/nlp-getting-started/train.csv\")\ndf_test = pd.read_csv(\"/kaggle/input/nlp-getting-started/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-09-17T14:01:59.662414Z","iopub.execute_input":"2023-09-17T14:01:59.662754Z","iopub.status.idle":"2023-09-17T14:01:59.722867Z","shell.execute_reply.started":"2023-09-17T14:01:59.662722Z","shell.execute_reply":"2023-09-17T14:01:59.721968Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"df_train.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-17T14:01:59.726109Z","iopub.execute_input":"2023-09-17T14:01:59.726380Z","iopub.status.idle":"2023-09-17T14:01:59.745540Z","shell.execute_reply.started":"2023-09-17T14:01:59.726356Z","shell.execute_reply":"2023-09-17T14:01:59.744486Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"   id keyword location                                               text  \\\n0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n\n   target  \n0       1  \n1       1  \n2       1  \n3       1  \n4       1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Our Deeds are the Reason of this #earthquake M...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Forest fire near La Ronge Sask. Canada</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>All residents asked to 'shelter in place' are ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>13,000 people receive #wildfires evacuation or...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Extracting text and targets","metadata":{}},{"cell_type":"code","source":"src = df_train['text']\ntgt = df_train['target']","metadata":{"execution":{"iopub.status.busy":"2023-09-17T14:01:59.748310Z","iopub.execute_input":"2023-09-17T14:01:59.748641Z","iopub.status.idle":"2023-09-17T14:01:59.753396Z","shell.execute_reply.started":"2023-09-17T14:01:59.748610Z","shell.execute_reply":"2023-09-17T14:01:59.752366Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Setting up device for GPU\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2023-09-17T14:01:59.754950Z","iopub.execute_input":"2023-09-17T14:01:59.755340Z","iopub.status.idle":"2023-09-17T14:01:59.785779Z","shell.execute_reply.started":"2023-09-17T14:01:59.755309Z","shell.execute_reply":"2023-09-17T14:01:59.784725Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"## Tokenization data using pretrained bert model from HuggingFace","metadata":{}},{"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained('bert-large-uncased')","metadata":{"execution":{"iopub.status.busy":"2023-09-17T14:01:59.787283Z","iopub.execute_input":"2023-09-17T14:01:59.787665Z","iopub.status.idle":"2023-09-17T14:02:01.114124Z","shell.execute_reply.started":"2023-09-17T14:01:59.787629Z","shell.execute_reply":"2023-09-17T14:02:01.112945Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"49baa7e4306c440982ec6ea6971140ce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dee9b722dad44c1eb15406074657268d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"17d61fe9e5684a6b8452930835a5c349"}},"metadata":{}}]},{"cell_type":"code","source":"encoded_data = tokenizer.batch_encode_plus(\n    src,\n    padding=True,\n    truncation=True,\n    max_length=512,\n    return_tensors='pt'\n)","metadata":{"execution":{"iopub.status.busy":"2023-09-17T14:02:01.115618Z","iopub.execute_input":"2023-09-17T14:02:01.116059Z","iopub.status.idle":"2023-09-17T14:02:07.803189Z","shell.execute_reply.started":"2023-09-17T14:02:01.116026Z","shell.execute_reply":"2023-09-17T14:02:07.802154Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class CustomDataset(torch.utils.data.Dataset):\n    def __init__(self, encoded_data, labels=None):\n        self.input_ids = encoded_data['input_ids']\n        self.attention_mask = encoded_data['attention_mask']\n        self.labels = torch.tensor(labels) if labels is not None else None\n        \n    def __len__(self):\n        return len(self.input_ids)\n    \n    def __getitem__(self, idx):\n        if self.labels is None:\n            return {\n                'input_ids': self.input_ids[idx],\n                'attention_mask': self.attention_mask[idx],\n            }\n\n        return {\n            'input_ids': self.input_ids[idx],\n            'attention_mask': self.attention_mask[idx],\n            'labels': self.labels[idx]\n        }\n    \ndataset = CustomDataset(encoded_data, tgt)","metadata":{"execution":{"iopub.status.busy":"2023-09-17T14:02:07.804824Z","iopub.execute_input":"2023-09-17T14:02:07.805302Z","iopub.status.idle":"2023-09-17T14:02:07.853959Z","shell.execute_reply.started":"2023-09-17T14:02:07.805269Z","shell.execute_reply":"2023-09-17T14:02:07.853056Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import random_split\n\ntrain_size = int(0.8 * len(dataset))\nval_size = len(dataset) - train_size\ntrain_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n\nprint(len(train_dataset), len(val_dataset))","metadata":{"execution":{"iopub.status.busy":"2023-09-17T14:02:07.855270Z","iopub.execute_input":"2023-09-17T14:02:07.855695Z","iopub.status.idle":"2023-09-17T14:02:07.876021Z","shell.execute_reply.started":"2023-09-17T14:02:07.855661Z","shell.execute_reply":"2023-09-17T14:02:07.874996Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"6090 1523\n","output_type":"stream"}]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\nbatch_size = 16\n\ntrain_loader = DataLoader(\n    dataset=train_dataset,\n    batch_size=batch_size, \n    shuffle=True\n)\n\nval_loader = DataLoader(\n    dataset=val_dataset,\n    batch_size=batch_size,\n    shuffle=True\n)","metadata":{"execution":{"iopub.status.busy":"2023-09-17T14:02:07.879486Z","iopub.execute_input":"2023-09-17T14:02:07.879772Z","iopub.status.idle":"2023-09-17T14:02:07.886783Z","shell.execute_reply.started":"2023-09-17T14:02:07.879748Z","shell.execute_reply":"2023-09-17T14:02:07.885764Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## Define train % validation functions","metadata":{}},{"cell_type":"code","source":"@torch.no_grad()\ndef validate_model(model, val_loader):\n    model.eval()\n    \n    correct_samples = 0\n    total_samples = 0\n    \n    for batch in val_loader:\n        input_ids = batch['input_ids'].to(device)\n        attention_mask =  batch['attention_mask'].to(device)\n        labels = batch['labels'].to(device)\n        \n        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n        logits = outputs.logits\n        \n        _, indices = torch.max(logits, 1)\n        correct_samples += torch.sum(indices == labels)\n        total_samples += labels.shape[0]\n        \n    return float(correct_samples) / total_samples","metadata":{"execution":{"iopub.status.busy":"2023-09-17T14:02:07.888308Z","iopub.execute_input":"2023-09-17T14:02:07.888808Z","iopub.status.idle":"2023-09-17T14:02:07.896820Z","shell.execute_reply.started":"2023-09-17T14:02:07.888776Z","shell.execute_reply":"2023-09-17T14:02:07.895922Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def train_model(model, optimizer, train_loader, val_loader, num_epochs):\n    train_losses = []\n    \n    train_accuracies = []\n    val_accuracies = []\n    \n    for epoch in range(num_epochs):\n        model.train()\n\n        running_loss = 0.0\n\n        correct_samples = 0\n        total_samples = 0\n\n        for batch in train_loader:\n            input_ids = batch['input_ids'].to(device)\n            attention_mask =  batch['attention_mask'].to(device)\n            labels = batch['labels'].to(device)\n\n            optimizer.zero_grad()\n\n            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n            loss = outputs.loss\n            logits = outputs.logits\n\n            loss.backward()\n            optimizer.step()\n\n            running_loss += loss.item()\n\n            _, indices = torch.max(logits, 1)\n            correct_samples += torch.sum(indices == labels)\n            total_samples += labels.shape[0]    \n\n        epoch_loss = running_loss / len(train_loader)\n\n        train_accuracy = float(correct_samples) / total_samples\n        val_accuracy = validate_model(model, val_loader)\n\n        print(f\"Epoch: {epoch+1}/{num_epochs} | Train Loss: {epoch_loss:.16f} | Train Accuracy: {train_accuracy:.4f} | Validation Accuracy: {val_accuracy:.4f}\")\n        \n#         train_losses.append(epoch_loss)\n\n#         train_accuracies.append(train_accuracy)\n#         val_accuracies.append(val_accuracy)\n        \n    return train_losses, train_accuracies, val_accuracies","metadata":{"execution":{"iopub.status.busy":"2023-09-17T14:02:07.898343Z","iopub.execute_input":"2023-09-17T14:02:07.898732Z","iopub.status.idle":"2023-09-17T14:02:07.912321Z","shell.execute_reply.started":"2023-09-17T14:02:07.898701Z","shell.execute_reply":"2023-09-17T14:02:07.911299Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"## Hyper-parameter tunning using randomized approach","metadata":{}},{"cell_type":"code","source":"# Explanation: \n# Getting every search iteration random learning rate and weight decay from uniform distribution.\n# Initially you should set bounds to np.random.uniform from (-7, -1) approximately.\n# Number of epochs for each tuning step is around 3-4, I've set it to 3.\n# After search is done you can select new bound i.e. (-5, -3) and repeat this process again.\n# You can do it until you find a good learning rate and weight decay parameters and then use it to your model\n\n# random_search_iters = 5\n# for it in range(random_search_iters):\n#     lr = 10**np.random.uniform(-6, -4)\n#     weight_decay = 10**np.random.uniform(-6, -2)\n    \n#     print()\n#     print(f\"Iteration {it+1}/{random_search_iters} for randomized search.\")\n#     print(f\"Learning rate: {lr} | Weight decay: {weight_decay}\")\n#     print()\n    \n#     model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n#     model.to(device)\n\n#     optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n    \n#     train_model(model, optimizer, train_loader, val_loader, 3)","metadata":{"execution":{"iopub.status.busy":"2023-09-17T14:02:07.913609Z","iopub.execute_input":"2023-09-17T14:02:07.915287Z","iopub.status.idle":"2023-09-17T14:02:07.926594Z","shell.execute_reply.started":"2023-09-17T14:02:07.915254Z","shell.execute_reply":"2023-09-17T14:02:07.925635Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"lr = 5.9891071551069174e-06\nweight_decay = 1.850822698520024e-04\n\nmodel = BertForSequenceClassification.from_pretrained('bert-large-uncased', num_labels=2)\nmodel.to(device)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)","metadata":{"execution":{"iopub.status.busy":"2023-09-17T14:02:07.928943Z","iopub.execute_input":"2023-09-17T14:02:07.929232Z","iopub.status.idle":"2023-09-17T14:02:23.176554Z","shell.execute_reply.started":"2023-09-17T14:02:07.929209Z","shell.execute_reply":"2023-09-17T14:02:23.175560Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/1.34G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2fe6ba719a814261bcdd444b7e095e45"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"train_losses, train_accuracies, val_accuracies = train_model(model, optimizer, train_loader, val_loader, num_epochs=3)","metadata":{"execution":{"iopub.status.busy":"2023-09-17T14:02:23.177879Z","iopub.execute_input":"2023-09-17T14:02:23.178330Z","iopub.status.idle":"2023-09-17T14:11:43.090073Z","shell.execute_reply.started":"2023-09-17T14:02:23.178295Z","shell.execute_reply":"2023-09-17T14:11:43.088967Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Epoch: 1/3 | Train Loss: 0.4695580268860489 | Train Accuracy: 0.7959 | Validation Accuracy: 0.8332\nEpoch: 2/3 | Train Loss: 0.3588918076725457 | Train Accuracy: 0.8580 | Validation Accuracy: 0.8385\nEpoch: 3/3 | Train Loss: 0.3198460609385660 | Train Accuracy: 0.8744 | Validation Accuracy: 0.8411\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Predict test data & save outputs","metadata":{}},{"cell_type":"code","source":"src_test = df_test['text'] \nidxs_test = df_test['id']","metadata":{"execution":{"iopub.status.busy":"2023-09-17T14:24:56.506204Z","iopub.execute_input":"2023-09-17T14:24:56.506772Z","iopub.status.idle":"2023-09-17T14:24:56.512323Z","shell.execute_reply.started":"2023-09-17T14:24:56.506741Z","shell.execute_reply":"2023-09-17T14:24:56.511217Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"encoded_data_test = tokenizer.batch_encode_plus(\n    src_test,\n    padding=True,\n    truncation=True,\n    max_length=512,\n    return_tensors='pt'\n)","metadata":{"execution":{"iopub.status.busy":"2023-09-17T14:24:56.689874Z","iopub.execute_input":"2023-09-17T14:24:56.690543Z","iopub.status.idle":"2023-09-17T14:24:59.639617Z","shell.execute_reply.started":"2023-09-17T14:24:56.690508Z","shell.execute_reply":"2023-09-17T14:24:59.638625Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"test_dataset = CustomDataset(encoded_data_test)","metadata":{"execution":{"iopub.status.busy":"2023-09-17T14:24:59.642635Z","iopub.execute_input":"2023-09-17T14:24:59.643382Z","iopub.status.idle":"2023-09-17T14:24:59.648129Z","shell.execute_reply.started":"2023-09-17T14:24:59.643343Z","shell.execute_reply":"2023-09-17T14:24:59.647142Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"test_loader = DataLoader(\n    dataset=test_dataset,\n    batch_size=batch_size, \n)","metadata":{"execution":{"iopub.status.busy":"2023-09-17T14:24:59.649446Z","iopub.execute_input":"2023-09-17T14:24:59.650151Z","iopub.status.idle":"2023-09-17T14:24:59.660978Z","shell.execute_reply.started":"2023-09-17T14:24:59.650085Z","shell.execute_reply":"2023-09-17T14:24:59.659872Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"model.eval()\n    \npredicted_indices = []\n    \nfor batch in test_loader:\n    input_ids = batch['input_ids'].to(device)\n    attention_mask =  batch['attention_mask'].to(device)\n        \n    outputs = model(input_ids, attention_mask=attention_mask)\n    logits = outputs.logits\n        \n    _, indices = torch.max(logits, 1)\n    predicted_indices.extend([int(i) for i in indices])","metadata":{"execution":{"iopub.status.busy":"2023-09-17T14:24:59.664961Z","iopub.execute_input":"2023-09-17T14:24:59.665338Z","iopub.status.idle":"2023-09-17T14:25:24.676465Z","shell.execute_reply.started":"2023-09-17T14:24:59.665298Z","shell.execute_reply":"2023-09-17T14:25:24.675476Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"output = pd.DataFrame({\n    \"id\": idxs_test,\n    \"target\": predicted_indices\n})","metadata":{"execution":{"iopub.status.busy":"2023-09-17T14:25:24.678676Z","iopub.execute_input":"2023-09-17T14:25:24.679500Z","iopub.status.idle":"2023-09-17T14:25:24.687279Z","shell.execute_reply.started":"2023-09-17T14:25:24.679464Z","shell.execute_reply":"2023-09-17T14:25:24.686270Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"output.head(3)","metadata":{"execution":{"iopub.status.busy":"2023-09-17T14:25:24.690140Z","iopub.execute_input":"2023-09-17T14:25:24.690462Z","iopub.status.idle":"2023-09-17T14:25:24.703667Z","shell.execute_reply.started":"2023-09-17T14:25:24.690429Z","shell.execute_reply":"2023-09-17T14:25:24.702626Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"   id  target\n0   0       0\n1   2       1\n2   3       1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"output.to_csv(\"pretrained_bert_5.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2023-09-17T14:25:24.705748Z","iopub.execute_input":"2023-09-17T14:25:24.706190Z","iopub.status.idle":"2023-09-17T14:25:24.724540Z","shell.execute_reply.started":"2023-09-17T14:25:24.706156Z","shell.execute_reply":"2023-09-17T14:25:24.723714Z"},"trusted":true},"execution_count":23,"outputs":[]}]}